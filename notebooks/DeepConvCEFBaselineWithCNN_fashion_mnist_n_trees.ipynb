{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"legend.loc\"] = \"best\"\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter python warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Fashion MNIST data\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# train data\n",
    "mnist_trainset = datasets.FashionMNIST(root='./data/fashion', train=True, download=True, transform=None)\n",
    "mnist_train_images = mnist_trainset.train_data.numpy()[..., np.newaxis]\n",
    "mnist_train_labels = mnist_trainset.train_labels.numpy()\n",
    "\n",
    "# test data\n",
    "mnist_testset = datasets.FashionMNIST(root='./data/fashion', train=False, download=True, transform=None)\n",
    "mnist_test_images = mnist_testset.test_data.numpy()[..., np.newaxis]\n",
    "mnist_test_labels = mnist_testset.test_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Entropy Forests (For better posterior estimates)\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def cef_estimate_posterior(X, y, n_estimators = 200, max_samples = .32, bootstrap = True, depth = 30, min_samples_leaf = 1):\n",
    "    model = BaggingClassifier(DecisionTreeClassifier(max_depth = depth, min_samples_leaf = min_samples_leaf), \n",
    "                              n_estimators = n_estimators, \n",
    "                              max_samples= max_samples, \n",
    "                              bootstrap = bootstrap)\n",
    "    model.fit(X, y)\n",
    "    class_counts = np.zeros((X.shape[0], model.n_classes_))\n",
    "    for tree in model:\n",
    "        # get out of bag indicies\n",
    "        unsampled_indices = _generate_unsampled_indices(tree.random_state, len(X))\n",
    "        \n",
    "        total_unsampled = len(unsampled_indices)\n",
    "        np.random.shuffle(unsampled_indices)\n",
    "        prob_indices, eval_indices = unsampled_indices[:total_unsampled//2], unsampled_indices[total_unsampled//2:]\n",
    "        # get all node counts\n",
    "        node_counts = tree.tree_.n_node_samples\n",
    "        # get probs for eval samples\n",
    "        posterior_class_counts = np.zeros((len(node_counts), model.n_classes_))\n",
    "        for prob_index in prob_indices:\n",
    "            posterior_class_counts[tree.apply([[X[prob_index].item()]]).item(), y[prob_index]] += 1\n",
    "        row_sums = posterior_class_counts.sum(axis=1)\n",
    "        row_sums[row_sums == 0] = 1\n",
    "        class_probs = (posterior_class_counts/row_sums[:, None])\n",
    "        where_0 = np.argwhere(class_probs == 0)\n",
    "        for elem in where_0:\n",
    "            class_probs[elem[0], elem[1]] = 1/(2*row_sums[elem[0], None])\n",
    "        where_1 = np.argwhere(class_probs == 1)\n",
    "        for elem in where_1:\n",
    "            class_probs[elem[0], elem[1]] = 1 - 1/(2*row_sums[elem[0], None])\n",
    "        class_probs.tolist()\n",
    "        partition_counts = np.asarray([node_counts[x] for x in tree.apply(X[eval_indices])])\n",
    "        # get probability for out of bag samples\n",
    "        eval_class_probs = [class_probs[x] for x in tree.apply(X[eval_indices])]\n",
    "        eval_class_probs = np.array(eval_class_probs)\n",
    "        # find total elements for out of bag samples\n",
    "        elems = np.multiply(eval_class_probs, partition_counts[:, np.newaxis])\n",
    "        # store counts for each x (repeat this for each tree)\n",
    "        class_counts[eval_indices] += elems\n",
    "    # calculate p(y|X = x) for all x's\n",
    "    probs = class_counts/class_counts.sum(axis = 1, keepdims = True)\n",
    "    print(probs.shape)\n",
    "    neg_one_class, one_class = np.hsplit(probs, 2)\n",
    "    return X, neg_one_class, one_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# test if cef works\n",
    "def get_sample(n, mean, var):\n",
    "    x_sample = []\n",
    "    y_sample = []\n",
    "    for i in range(n):\n",
    "        y = np.random.binomial(1, .5)\n",
    "        if (y == 0):\n",
    "            x = np.random.normal(-mean, var)\n",
    "        else:\n",
    "            x = np.random.normal(mean, var)\n",
    "        x_sample.append(x)\n",
    "        y_sample.append(y)\n",
    "    return x_sample, y_sample\n",
    "\n",
    "X, y = get_sample(1000, 1, 1)\n",
    "X = np.array(X).reshape(-1, 1)\n",
    "\n",
    "X_labels_cef, neg_one_class_cef, one_class_cef = cef_estimate_posterior(X, y, 100, .32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Deep Convolution CEF class (for binary classification)\n",
    "class ConvCEF(object):\n",
    "    def __init__(self, kernel_size=5, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.kernel_forests = None\n",
    "\n",
    "    def _convolve_chop(self, images, labels=None, flatten=False):\n",
    "\n",
    "        batch_size, in_dim, _, num_channels = images.shape\n",
    "\n",
    "        out_dim = int((in_dim - self.kernel_size) / self.stride) + 1  # calculate output dimensions\n",
    "\n",
    "        # create matrix to hold the chopped images\n",
    "        out_images = np.zeros((batch_size, out_dim, out_dim,\n",
    "                               self.kernel_size, self.kernel_size, num_channels))\n",
    "        out_labels = None\n",
    "\n",
    "        curr_y = out_y = 0\n",
    "        # move kernel vertically across the image\n",
    "        while curr_y + self.kernel_size <= in_dim:\n",
    "            curr_x = out_x = 0\n",
    "            # move kernel horizontally across the image\n",
    "            while curr_x + self.kernel_size <= in_dim:\n",
    "                # chop images\n",
    "                out_images[:, out_x, out_y] = images[:, curr_x:curr_x +\n",
    "                                                     self.kernel_size, curr_y:curr_y+self.kernel_size, :]\n",
    "                curr_x += self.stride\n",
    "                out_x += 1\n",
    "            curr_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        if flatten:\n",
    "            out_images = out_images.reshape(batch_size, out_dim, out_dim, -1)\n",
    "\n",
    "        if labels is not None:\n",
    "            out_labels = np.zeros((batch_size, out_dim, out_dim))\n",
    "            out_labels[:, ] = labels.reshape(-1, 1, 1)\n",
    "\n",
    "        return out_images, out_labels\n",
    "\n",
    "    def convolve_fit(self, images, labels):\n",
    "        num_channels = images.shape[-1]\n",
    "        sub_images, sub_labels = self._convolve_chop(images, labels=labels, flatten=True)\n",
    "\n",
    "        batch_size, out_dim, _, _ = sub_images.shape\n",
    "        self.kernel_forests = np.zeros((out_dim, out_dim), dtype=np.int).tolist()\n",
    "        convolved_image = np.zeros((images.shape[0], out_dim, out_dim, 1))\n",
    "        \n",
    "        for i in range(out_dim):\n",
    "            for j in range(out_dim):\n",
    "                self.kernel_forests[i][j].fit(sub_images[:, i, j], sub_labels[:, i, j])\n",
    "                convolved_image[:, i, j] = self.kernel_forests[i][j].predict_proba(sub_images[:, i, j])[..., 1][..., np.newaxis]\n",
    "        return convolved_image\n",
    "\n",
    "    def convolve_predict(self, images):\n",
    "        if not self.kernel_forests:\n",
    "            raise Exception(\"Should fit training data before predicting\")\n",
    "\n",
    "        num_channels = images.shape[-1]\n",
    "        sub_images, _ = self._convolve_chop(images, flatten=True)\n",
    "\n",
    "        batch_size, out_dim, _, _ = sub_images.shape\n",
    "        \n",
    "        kernel_predictions = np.zeros((images.shape[0], out_dim, out_dim, 1))\n",
    "        \n",
    "        for i in range(out_dim):\n",
    "            for j in range(out_dim):\n",
    "                kernel_predictions[:, i, j] = self.kernel_forests[i][j].predict_proba(sub_images[:, i, j])[..., 1][..., np.newaxis]\n",
    "        return kernel_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
