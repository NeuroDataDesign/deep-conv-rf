{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/py3/envs/ML/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRF(object):\n",
    "    def __init__(self, kernel_size=5, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.kernel_forests = None\n",
    "        self.num_outputs = 10\n",
    "\n",
    "    def _convolve_chop(self, images, labels=None, flatten=False):\n",
    "\n",
    "        batch_size, in_dim, _, num_channels = images.shape\n",
    "\n",
    "        out_dim = int((in_dim - self.kernel_size) / self.stride) + 1  # calculate output dimensions\n",
    "\n",
    "        # create matrix to hold the chopped images\n",
    "        out_images = np.zeros((batch_size, out_dim, out_dim,\n",
    "                               self.kernel_size, self.kernel_size, num_channels))\n",
    "        out_labels = None\n",
    "\n",
    "        curr_y = out_y = 0\n",
    "        # move kernel vertically across the image\n",
    "        while curr_y + self.kernel_size <= in_dim:\n",
    "            curr_x = out_x = 0\n",
    "            # move kernel horizontally across the image\n",
    "            while curr_x + self.kernel_size <= in_dim:\n",
    "                # chop images\n",
    "                out_images[:, out_x, out_y] = images[:, curr_x:curr_x +\n",
    "                                                     self.kernel_size, curr_y:curr_y+self.kernel_size, :]\n",
    "                curr_x += self.stride\n",
    "                out_x += 1\n",
    "            curr_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        if flatten:\n",
    "            out_images = out_images.reshape(batch_size, out_dim, out_dim, -1)\n",
    "\n",
    "        if labels is not None:\n",
    "            out_labels = np.zeros((batch_size, out_dim, out_dim))\n",
    "            out_labels[:, ] = labels.reshape(-1, 1, 1)\n",
    "\n",
    "        return out_images, out_labels\n",
    "\n",
    "    def convolve_fit(self, images, labels):\n",
    "        num_channels = images.shape[-1]\n",
    "        self.num_outputs = len(np.unique(labels))\n",
    "        \n",
    "        # check if this is the raw input image, to decide to flatten or not\n",
    "        flatten = True if num_channels in (1, 3) else False\n",
    "        sub_images, sub_labels = self._convolve_chop(images, labels=labels, flatten=flatten)\n",
    "\n",
    "        if flatten:\n",
    "            batch_size, out_dim, _, features = sub_images.shape\n",
    "            self.kernel_forests = np.zeros((out_dim, out_dim), dtype=np.int).tolist()\n",
    "        else:\n",
    "            batch_size, out_dim, _, kernel_size, _, num_channels = sub_images.shape\n",
    "            self.kernel_forests = np.zeros((out_dim, out_dim, num_channels), dtype=np.int).tolist()\n",
    "        \n",
    "        convolved_image = np.zeros((images.shape[0], out_dim, out_dim, self.num_outputs))\n",
    "        \n",
    "        for i in range(out_dim):\n",
    "            for j in range(out_dim):\n",
    "                if not flatten:\n",
    "                    for k in range(num_channels):\n",
    "                        self.kernel_forests[i][j][k] = RandomForestClassifier(n_estimators=self.num_outputs)\n",
    "                        self.kernel_forests[i][j][k].fit(sub_images[:, i, j, :, :, k].reshape(batch_size, -1), sub_labels[:, i, j])\n",
    "                        convolved_image[:, i, j, k] = np.max(self.kernel_forests[i][j][k].apply(sub_images[:, i, j, :, :, k].reshape(batch_size, -1)), axis=1)\n",
    "                else:\n",
    "                    self.kernel_forests[i][j] = RandomForestClassifier(n_estimators=self.num_outputs)\n",
    "                    self.kernel_forests[i][j].fit(sub_images[:, i, j], sub_labels[:, i, j])\n",
    "                    convolved_image[:, i, j] = self.kernel_forests[i][j].apply(sub_images[:, i, j])\n",
    "        return convolved_image\n",
    "\n",
    "    def convolve_predict(self, images):\n",
    "        if not self.kernel_forests:\n",
    "            raise Exception(\"Should fit training data before predicting\")\n",
    "\n",
    "        num_channels = images.shape[-1]\n",
    "        \n",
    "        # check if this is the raw input image, to decide to flatten or not\n",
    "        flatten = True if num_channels in (1, 3) else False\n",
    "        sub_images, _ = self._convolve_chop(images, flatten=flatten)\n",
    "\n",
    "        if flatten:\n",
    "            batch_size, out_dim, _, features = sub_images.shape\n",
    "        else:\n",
    "            batch_size, out_dim, _, kernel_size, _, num_channels = sub_images.shape\n",
    "        \n",
    "        kernel_predictions = np.zeros((images.shape[0], out_dim, out_dim, self.num_outputs))\n",
    "        \n",
    "        for i in range(out_dim):\n",
    "            for j in range(out_dim):\n",
    "                if not flatten:\n",
    "                    for k in range(num_channels):\n",
    "                        kernel_predictions[:, i, j, k] = np.max(self.kernel_forests[i][j][k].apply(sub_images[:, i, j, :, :, k].reshape(batch_size, -1)), axis=1)\n",
    "                else:\n",
    "                    kernel_predictions[:, i, j] = self.kernel_forests[i][j].apply(sub_images[:, i, j])\n",
    "        return kernel_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare MNIST data\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_train_images = mnist_trainset.train_data.numpy()[..., np.newaxis]\n",
    "mnist_train_labels = mnist_trainset.train_labels.numpy()\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "mnist_test_images = mnist_testset.test_data.numpy()[..., np.newaxis]\n",
    "mnist_test_labels = mnist_testset.test_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(mnist_train_images, mnist_train_labels, mnist_test_images, mnist_test_labels):\n",
    "    ##########################################################\n",
    "    print(\"Num. of Convolution Layers: 1\")\n",
    "    # conv layer 1\n",
    "    conv1 = ConvRF(kernel_size=3, stride=2)\n",
    "    conv1_map = conv1.convolve_fit(mnist_train_images, mnist_train_labels)\n",
    "    \n",
    "    # full RF (conv 1)\n",
    "    conv1_full_RF = RandomForestClassifier()\n",
    "#     conv1_full_RF.fit(np.argmax(conv1_map, axis=3).reshape(len(mnist_train_images), -1), mnist_train_labels)\n",
    "    conv1_full_RF.fit(conv1_map.reshape(len(mnist_train_images), -1), mnist_train_labels)\n",
    "    \n",
    "    # test (conv 1)\n",
    "    conv1_map_test = conv1.convolve_predict(mnist_test_images)\n",
    "#     mnist_test_preds = conv1_full_RF.predict(np.argmax(conv1_map_test, axis=3).reshape(len(mnist_test_images), -1))\n",
    "    mnist_test_preds = conv1_full_RF.predict(conv1_map_test.reshape(len(mnist_test_images), -1))\n",
    "\n",
    "    print(\"Test Accuracy: \" + str(accuracy_score(mnist_test_labels, mnist_test_preds)))\n",
    "    print(\"Validation Confusion Matrix: \\n\" + str(confusion_matrix(mnist_test_labels, mnist_test_preds)))\n",
    "    \n",
    "    ##########################################################\n",
    "    print(\"Num. of Convolution Layers: 2\")\n",
    "    # conv layer 2\n",
    "    conv2 = ConvRF(kernel_size=3, stride=2)\n",
    "    conv2_map = conv2.convolve_fit(conv1_map, mnist_train_labels)\n",
    "    \n",
    "    # full RF (conv 2)\n",
    "    conv2_full_RF = RandomForestClassifier()\n",
    "#     conv2_full_RF.fit(np.argmax(conv2_map, axis=3).reshape(len(mnist_train_images), -1), mnist_train_labels)\n",
    "    conv2_full_RF.fit(conv2_map.reshape(len(mnist_train_images), -1), mnist_train_labels)\n",
    "    \n",
    "    # test (conv 2)\n",
    "    conv2_map_test = conv2.convolve_predict(conv1_map_test)\n",
    "#     mnist_test_preds = conv2_full_RF.predict(np.argmax(conv2_map_test, axis=3).reshape(len(mnist_test_images), -1))\n",
    "    mnist_test_preds = conv2_full_RF.predict(conv2_map_test.reshape(len(mnist_test_images), -1))\n",
    "\n",
    "    print(\"Test Accuracy: \" + str(accuracy_score(mnist_test_labels, mnist_test_preds)))\n",
    "    print(\"Validation Confusion Matrix: \\n\" + str(confusion_matrix(mnist_test_labels, mnist_test_preds)))\n",
    "\n",
    "    ##########################################################\n",
    "    print(\"Num. of Convolution Layers: 3\")\n",
    "    # conv layer 3\n",
    "    conv3 = ConvRF(kernel_size=3, stride=1)\n",
    "    conv3_map = conv3.convolve_fit(conv2_map, mnist_train_labels)\n",
    "    \n",
    "    # full RF (conv 3)\n",
    "    conv3_full_RF = RandomForestClassifier()\n",
    "#     conv3_full_RF.fit(np.argmax(conv3_map, axis=3).reshape(len(mnist_train_images), -1), mnist_train_labels)\n",
    "    conv3_full_RF.fit(conv3_map.reshape(len(mnist_train_images), -1), mnist_train_labels)\n",
    "    \n",
    "    # test (conv 3)\n",
    "    conv3_map_test = conv3.convolve_predict(conv2_map_test)\n",
    "#     mnist_test_preds = conv3_full_RF.predict(np.argmax(conv3_map_test, axis=3).reshape(len(mnist_test_images), -1))\n",
    "    mnist_test_preds = conv3_full_RF.predict(conv3_map_test.reshape(len(mnist_test_images), -1))\n",
    "\n",
    "    print(\"Test Accuracy: \" + str(accuracy_score(mnist_test_labels, mnist_test_preds)))\n",
    "    print(\"Validation Confusion Matrix: \\n\" + str(confusion_matrix(mnist_test_labels, mnist_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Convolution Layers: 1\n",
      "Test Accuracy: 0.9512\n",
      "Validation Confusion Matrix: \n",
      "[[ 967    1    1    0    0    2    4    1    4    0]\n",
      " [   0 1119    4    3    1    1    1    1    5    0]\n",
      " [   9    0  985    4    6    0    2   11   13    2]\n",
      " [   3    1   19  952    0   12    0    9    7    7]\n",
      " [   2    1    2    1  930    1    6    5    7   27]\n",
      " [  11    3    4   32    2  820    8    2    5    5]\n",
      " [   6    4    2    1    4   15  920    0    6    0]\n",
      " [   3    4   19    4    4    1    0  978    4   11]\n",
      " [   8    2    7    9   11    9    7    5  907    9]\n",
      " [   9    5    5   11   21    6    0   13    5  934]]\n",
      "Num. of Convolution Layers: 2\n",
      "Test Accuracy: 0.9376\n",
      "Validation Confusion Matrix: \n",
      "[[ 967    1    0    0    1    2    2    2    4    1]\n",
      " [   1 1116    6    3    1    1    2    0    5    0]\n",
      " [   9    1  986    5    6    2    3   10   10    0]\n",
      " [   0    2   24  926    1   16    0   16   19    6]\n",
      " [   3    2    4    1  921    2    7    0   12   30]\n",
      " [  11    2    3   43    8  787   12    1   20    5]\n",
      " [   5    4    2    0    6    9  924    1    7    0]\n",
      " [   0    5   18   12    3    2    0  956    8   24]\n",
      " [   7    5    9   23    8   15    8    9  880   10]\n",
      " [   5    5    1   21   36    7    1   13    7  913]]\n",
      "Num. of Convolution Layers: 3\n",
      "Test Accuracy: 0.8914\n",
      "Validation Confusion Matrix: \n",
      "[[ 938    1    8    4    1    6    6    3   13    0]\n",
      " [   1 1107    6    2    0    2    3    2   12    0]\n",
      " [  15    3  941   14    7    7   10   17   17    1]\n",
      " [   5    3   48  833    3   55    1   27   26    9]\n",
      " [   5    0   10    5  869    6   13    6   18   50]\n",
      " [   7    9   13   77    9  710   10    7   38   12]\n",
      " [  14    4   11    1    9   20  890    0    8    1]\n",
      " [   1    5   23   13   10    8    0  926   16   26]\n",
      " [  10    7   22   25   15   30    5   11  835   14]\n",
      " [   6    3    5   28   54   17    2   15   14  865]]\n"
     ]
    }
   ],
   "source": [
    "# full depth until min_split = 2\n",
    "run_experiment(mnist_train_images, mnist_train_labels, mnist_test_images, mnist_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Convolution Layers: 1\n",
      "Test Accuracy: 0.81\n",
      "Validation Confusion Matrix: \n",
      "[[ 8  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 14  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  5  0  0  0  1  1  0  0]\n",
      " [ 0  0  1  9  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 12  1  0  0  0  1]\n",
      " [ 0  0  0  0  0  4  1  1  0  1]\n",
      " [ 0  0  2  0  2  0  6  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 14  0  1]\n",
      " [ 0  0  1  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  1  1  0  1  0  8]]\n",
      "Num. of Convolution Layers: 2\n",
      "Test Accuracy: 0.85\n",
      "Validation Confusion Matrix: \n",
      "[[ 8  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 14  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  6  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 10  1  0  0  0  0  0]\n",
      " [ 0  0  1  0  9  0  0  1  0  3]\n",
      " [ 0  0  0  0  0  7  0  0  0  0]\n",
      " [ 1  0  0  0  3  0  6  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 14  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  1  0  0  0  0 10]]\n",
      "Num. of Convolution Layers: 3\n",
      "Test Accuracy: 0.79\n",
      "Validation Confusion Matrix: \n",
      "[[ 8  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  1  0  0  0  0  0  1]\n",
      " [ 0  0  6  0  0  1  0  1  0  0]\n",
      " [ 0  0  0 11  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 12  0  1  0  1  0]\n",
      " [ 1  0  0  0  1  4  1  0  0  0]\n",
      " [ 0  0  1  0  2  1  5  0  0  1]\n",
      " [ 0  0  0  0  2  0  0 12  1  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# max_depth = 6\n",
    "run_experiment(mnist_train_images[:1000], mnist_train_labels[:1000], mnist_test_images[:100], mnist_test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
