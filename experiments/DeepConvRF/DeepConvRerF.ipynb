{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import sys\n",
    "import os.path\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import numpy as np\n",
    "from RerF import fastRerF, fastPredict\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sns.set()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# sys.stdout = open(\"deep_conv_rf_logs.txt\", \"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# Settings\n",
    "##########\n",
    "# base_path = \"\"\n",
    "base_path = \"rerf/3vs5/\"\n",
    "\n",
    "class_one = 3\n",
    "class_two = 5\n",
    "\n",
    "fraction_of_train_samples_space = np.geomspace(0.01, 0.35, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################\n",
    "# Data Preparation\n",
    "###########################################################################################################\n",
    "\n",
    "def normalize(x):\n",
    "    scale = np.mean(np.arange(0, 256))\n",
    "    return (x - scale) / scale\n",
    "\n",
    "\n",
    "# train data\n",
    "cifar_trainset = datasets.CIFAR10(root='../../data', train=True, download=True, transform=None)\n",
    "cifar_train_images = normalize(cifar_trainset.data)\n",
    "cifar_train_labels = np.array(cifar_trainset.targets)\n",
    "\n",
    "# test data\n",
    "cifar_testset = datasets.CIFAR10(root='../../data', train=False, download=True, transform=None)\n",
    "cifar_test_images = normalize(cifar_testset.data)\n",
    "cifar_test_labels = np.array(cifar_testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRF(object):\n",
    "    def __init__(self, kernel_size=5, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.kernel_forest = None\n",
    "        self.num_trees = 1000\n",
    "\n",
    "    def _convolve_chop(self, images, labels=None, flatten=False):\n",
    "\n",
    "        batch_size, in_dim, _, num_channels = images.shape\n",
    "\n",
    "        out_dim = int((in_dim - self.kernel_size) / self.stride) + 1  # calculate output dimensions\n",
    "\n",
    "        # create matrix to hold the chopped images\n",
    "        out_images = np.zeros((batch_size, out_dim, out_dim,\n",
    "                               self.kernel_size, self.kernel_size, num_channels))\n",
    "        out_labels = None\n",
    "\n",
    "        curr_y = out_y = 0\n",
    "        # move kernel vertically across the image\n",
    "        while curr_y + self.kernel_size <= in_dim:\n",
    "            curr_x = out_x = 0\n",
    "            # move kernel horizontally across the image\n",
    "            while curr_x + self.kernel_size <= in_dim:\n",
    "                # chop images\n",
    "                out_images[:, out_x, out_y] = images[:, curr_x:curr_x +\n",
    "                                                     self.kernel_size, curr_y:curr_y+self.kernel_size, :]\n",
    "                curr_x += self.stride\n",
    "                out_x += 1\n",
    "            curr_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        if flatten:\n",
    "            out_images = out_images.reshape(batch_size, out_dim, out_dim, -1)\n",
    "\n",
    "        if labels is not None:\n",
    "            out_labels = np.zeros((batch_size, out_dim, out_dim))\n",
    "            out_labels[:, ] = labels.reshape(-1, 1, 1)\n",
    "\n",
    "        return out_images, out_labels\n",
    "\n",
    "    def convolve_fit(self, images, labels):\n",
    "        sub_images, sub_labels = self._convolve_chop(images, labels=labels, flatten=True)\n",
    "\n",
    "        batch_size, out_dim, _, _ = sub_images.shape\n",
    "\n",
    "        all_sub_images = sub_images.reshape(batch_size*out_dim*out_dim, -1)\n",
    "        all_sub_labels = sub_labels.reshape(batch_size*out_dim*out_dim, -1)\n",
    "\n",
    "        self.kernel_forest = fastRerF(X=all_sub_images,\n",
    "                                      Y=all_sub_labels,\n",
    "                                      forestType=\"binnedBase\",\n",
    "                                      trees=self.num_trees,\n",
    "                                      numCores=cpu_count() - 1)\n",
    "\n",
    "        convolved_image = np.zeros((images.shape[0], out_dim, out_dim, 1))\n",
    "        for i in range(out_dim):\n",
    "            for j in range(out_dim):\n",
    "                data = sub_images[:, i, j].flatten().tolist()\n",
    "                convolved_image[:, i, j] = np.array(self.kernel_forest.predict_post(data)[1] / float(self.num_trees))[..., np.newaxis]\n",
    "        return convolved_image\n",
    "\n",
    "    def convolve_predict(self, images):\n",
    "        if not self.kernel_forest:\n",
    "            raise Exception(\"Should fit training data before predicting\")\n",
    "\n",
    "        sub_images, _ = self._convolve_chop(images, flatten=True)\n",
    "\n",
    "        batch_size, out_dim, _, _ = sub_images.shape\n",
    "\n",
    "        kernel_predictions = np.zeros((images.shape[0], out_dim, out_dim, 1))\n",
    "\n",
    "        for i in range(out_dim):\n",
    "            for j in range(out_dim):\n",
    "                data = sub_images[:, i, j].flatten().tolist()\n",
    "                kernel_predictions[:, i, j] = np.array(self.kernel_forest.predict_post(data)[1] / float(self.num_trees))[..., np.newaxis]\n",
    "        return kernel_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naive_rf(train_images, train_labels, test_images, test_labels, fraction_of_train_samples, class1=3, class2=5):\n",
    "    num_train_samples_class_1 = int(np.sum(train_labels == class1) * fraction_of_train_samples)\n",
    "    num_train_samples_class_2 = int(np.sum(train_labels == class2) * fraction_of_train_samples)\n",
    "\n",
    "    # get only train images and labels for class 1 and class 2\n",
    "    train_images = np.concatenate([train_images[train_labels == class1][:num_train_samples_class_1],\n",
    "                                   train_images[train_labels == class2][:num_train_samples_class_2]])\n",
    "    train_labels = np.concatenate(\n",
    "        [np.repeat(0, num_train_samples_class_1), np.repeat(1, num_train_samples_class_2)])\n",
    "\n",
    "    # get only test images and labels for class 1 and class 2\n",
    "    test_images = np.concatenate([test_images[test_labels == class1],\n",
    "                                  test_images[test_labels == class2]])\n",
    "    test_labels = np.concatenate(\n",
    "        [np.repeat(0, np.sum(test_labels == class1)), np.repeat(1, np.sum(test_labels == class2))])\n",
    "\n",
    "    # Train\n",
    "    forest = fastRerF(X=train_images.reshape(-1, 32*32*3),\n",
    "                      Y=train_labels,\n",
    "                      forestType=\"binnedBase\",\n",
    "                      trees=100,\n",
    "                      numCores=cpu_count() - 1)\n",
    "    # forest.printParameters()\n",
    "\n",
    "    # Test\n",
    "    test_preds = fastPredict(test_images.reshape(-1, 32*32*3), forest)\n",
    "    return accuracy_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_layer_deep_conv_rf(train_images, train_labels, test_images, test_labels, fraction_of_train_samples, class1=3, class2=5):\n",
    "    num_train_samples_class_1 = int(np.sum(train_labels == class1) * fraction_of_train_samples)\n",
    "    num_train_samples_class_2 = int(np.sum(train_labels == class2) * fraction_of_train_samples)\n",
    "\n",
    "    # get only train images and labels for class 1 and class 2\n",
    "    train_images = np.concatenate([train_images[train_labels == class1][:num_train_samples_class_1],\n",
    "                                   train_images[train_labels == class2][:num_train_samples_class_2]])\n",
    "    train_labels = np.concatenate(\n",
    "        [np.repeat(0, num_train_samples_class_1), np.repeat(1, num_train_samples_class_2)])\n",
    "\n",
    "    # get only test images and labels for class 1 and class 2\n",
    "    test_images = np.concatenate([test_images[test_labels == class1],\n",
    "                                  test_images[test_labels == class2]])\n",
    "    test_labels = np.concatenate(\n",
    "        [np.repeat(0, np.sum(test_labels == class1)), np.repeat(1, np.sum(test_labels == class2))])\n",
    "\n",
    "    # Train\n",
    "    # ConvRF (layer 1)\n",
    "    conv1 = ConvRF(kernel_size=10, stride=2)\n",
    "    conv1_map = conv1.convolve_fit(train_images, train_labels)\n",
    "\n",
    "    # Full RF\n",
    "    conv1_full_RF = fastRerF(X=conv1_map.reshape(len(train_images), -1),\n",
    "                             Y=train_labels,\n",
    "                             forestType=\"binnedBase\",\n",
    "                             trees=100,\n",
    "                             numCores=cpu_count() - 1)\n",
    "\n",
    "    # Test (after ConvRF 1 and Full RF)\n",
    "    conv1_map_test = conv1.convolve_predict(test_images)\n",
    "    test_preds = fastPredict(conv1_map_test.reshape(len(test_images), -1), conv1_full_RF)\n",
    "\n",
    "    return accuracy_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_two_layer_deep_conv_rf(train_images, train_labels, test_images, test_labels, fraction_of_train_samples, class1=3, class2=5):\n",
    "    num_train_samples_class_1 = int(np.sum(train_labels == class1) * fraction_of_train_samples)\n",
    "    num_train_samples_class_2 = int(np.sum(train_labels == class2) * fraction_of_train_samples)\n",
    "\n",
    "    # get only train images and labels for class 1 and class 2\n",
    "    train_images = np.concatenate([train_images[train_labels == class1][:num_train_samples_class_1],\n",
    "                                   train_images[train_labels == class2][:num_train_samples_class_2]])\n",
    "    train_labels = np.concatenate(\n",
    "        [np.repeat(0, num_train_samples_class_1), np.repeat(1, num_train_samples_class_2)])\n",
    "\n",
    "    # get only test images and labels for class 1 and class 2\n",
    "    test_images = np.concatenate([test_images[test_labels == class1],\n",
    "                                  test_images[test_labels == class2]])\n",
    "    test_labels = np.concatenate(\n",
    "        [np.repeat(0, np.sum(test_labels == class1)), np.repeat(1, np.sum(test_labels == class2))])\n",
    "\n",
    "    # Train\n",
    "    # ConvRF (layer 1)\n",
    "    conv1 = ConvRF(kernel_size=10, stride=2)\n",
    "    conv1_map = conv1.convolve_fit(train_images, train_labels)\n",
    "\n",
    "    # ConvRF (layer 2)\n",
    "    conv2 = ConvRF(kernel_size=7, stride=1)\n",
    "    conv2_map = conv2.convolve_fit(conv1_map, train_labels)\n",
    "\n",
    "    # Full RF\n",
    "    conv1_full_RF = fastRerF(X=conv2_map.reshape(len(train_images), -1),\n",
    "                             Y=train_labels,\n",
    "                             forestType=\"binnedBase\",\n",
    "                             trees=100,\n",
    "                             numCores=cpu_count() - 1)\n",
    "\n",
    "    # Test (after ConvRF 2 and Full RF)\n",
    "    conv1_map_test = conv1.convolve_predict(test_images)\n",
    "    conv2_map_test = conv2.convolve_predict(conv1_map_test)\n",
    "    test_preds = fastPredict(conv2_map_test.reshape(len(test_images), -1), conv1_full_RF)\n",
    "\n",
    "    return accuracy_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Experiments\n",
    "###############################################################################\n",
    "\n",
    "def print_old_results(file_name):\n",
    "    global fraction_of_train_samples_space\n",
    "    accuracy_scores = np.load(file_name)\n",
    "    for fraction_of_train_samples, (best_accuracy, time_taken) in zip(fraction_of_train_samples_space, accuracy_scores):\n",
    "        print(\"Train Fraction:\", str(fraction_of_train_samples))\n",
    "        print(\"Accuracy:\", str(best_accuracy))\n",
    "        print(\"Experiment Runtime: \" + str(time_taken), \"\\n\")\n",
    "        print()\n",
    "    return accuracy_scores\n",
    "\n",
    "\n",
    "def run_experiment(experiment, experiment_result_file, text, cnn_model=None, class1=class_one, class2=class_two):\n",
    "    global fraction_of_train_samples_space\n",
    "    repeats = 2\n",
    "\n",
    "    print(\"##################################################################\")\n",
    "    print(\"acc vs n_samples: \" + text + \"\\n\")\n",
    "    acc_vs_n = list()\n",
    "    file_name = base_path+experiment_result_file+\".npy\"\n",
    "    if not os.path.exists(file_name):\n",
    "        for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "            if not cnn_model:\n",
    "                start = time.time()\n",
    "                best_accuracy = np.mean([experiment(cifar_train_images, cifar_train_labels, cifar_test_images,\n",
    "                                                    cifar_test_labels, fraction_of_train_samples, class1, class2) for _ in range(repeats)])\n",
    "                end = time.time()\n",
    "            else:\n",
    "                start = time.time()\n",
    "                best_accuracy = np.mean([experiment(cnn_model, cifar_train_images, cifar_train_labels, cifar_test_images,\n",
    "                                                    cifar_test_labels, fraction_of_train_samples, class1, class2) for _ in range(repeats)])\n",
    "                end = time.time()\n",
    "            time_taken = (end - start)/float(repeats)\n",
    "            acc_vs_n.append((best_accuracy, time_taken))\n",
    "            print(\"Train Fraction:\", str(fraction_of_train_samples))\n",
    "            print(\"Accuracy:\", str(best_accuracy))\n",
    "            print(\"Experiment Runtime: \" + str(time_taken), \"\\n\")\n",
    "        np.save(file_name, acc_vs_n)\n",
    "    else:\n",
    "        acc_vs_n = print_old_results(file_name)\n",
    "    print(\"##################################################################\")\n",
    "\n",
    "    return acc_vs_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "acc vs n_samples: Naive RF\n",
      "\n",
      "Train Fraction: 0.01\n",
      "Accuracy: 0.50725\n",
      "Experiment Runtime: 0.34542524814605713 \n",
      "\n",
      "\n",
      "Train Fraction: 0.014844415983612417\n",
      "Accuracy: 0.5217499999999999\n",
      "Experiment Runtime: 0.21671605110168457 \n",
      "\n",
      "\n",
      "Train Fraction: 0.02203566858945278\n",
      "Accuracy: 0.52825\n",
      "Experiment Runtime: 0.27205920219421387 \n",
      "\n",
      "\n",
      "Train Fraction: 0.03271066310188591\n",
      "Accuracy: 0.5722499999999999\n",
      "Experiment Runtime: 0.3542443513870239 \n",
      "\n",
      "\n",
      "Train Fraction: 0.04855706901841959\n",
      "Accuracy: 0.573\n",
      "Experiment Runtime: 0.476399302482605 \n",
      "\n",
      "\n",
      "Train Fraction: 0.07208013314543994\n",
      "Accuracy: 0.6105\n",
      "Experiment Runtime: 0.7783915996551514 \n",
      "\n",
      "\n",
      "Train Fraction: 0.10699874805650797\n",
      "Accuracy: 0.60475\n",
      "Experiment Runtime: 1.068491816520691 \n",
      "\n",
      "\n",
      "Train Fraction: 0.1588333925876545\n",
      "Accuracy: 0.61625\n",
      "Experiment Runtime: 1.6027202606201172 \n",
      "\n",
      "\n",
      "Train Fraction: 0.23577889516595646\n",
      "Accuracy: 0.6339999999999999\n",
      "Experiment Runtime: 2.341895341873169 \n",
      "\n",
      "\n",
      "Train Fraction: 0.35\n",
      "Accuracy: 0.6605000000000001\n",
      "Experiment Runtime: 4.150073885917664 \n",
      "\n",
      "\n",
      "##################################################################\n"
     ]
    }
   ],
   "source": [
    "naive_rf_acc_vs_n, naive_rf_acc_vs_n_times = list(zip(*run_experiment(run_naive_rf, \"naive_rf_acc_vs_n\", \"Naive RF\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "acc vs n_samples: DeepConvRF (shared)\n",
      "\n",
      "Train Fraction: 0.01\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 10.679657816886902 \n",
      "\n",
      "Train Fraction: 0.014844415983612417\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 6.628674149513245 \n",
      "\n",
      "Train Fraction: 0.02203566858945278\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 7.467689633369446 \n",
      "\n",
      "Train Fraction: 0.03271066310188591\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 8.483198761940002 \n",
      "\n",
      "Train Fraction: 0.04855706901841959\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 11.910579562187195 \n",
      "\n",
      "Train Fraction: 0.07208013314543994\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 14.807709813117981 \n",
      "\n",
      "Train Fraction: 0.10699874805650797\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 19.79778015613556 \n",
      "\n",
      "Train Fraction: 0.1588333925876545\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 34.35388112068176 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "deep_conv_rf_acc_vs_n, deep_conv_rf_acc_vs_n_times = list(zip(*run_experiment(run_one_layer_deep_conv_rf, \"deep_conv_rf_acc_vs_n\", \"DeepConvRF (shared)\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "acc vs n_samples: DeepConvRF (2-layer, shared)\n",
      "\n",
      "Train Fraction: 0.01\n",
      "Accuracy: 0.5\n",
      "Experiment Runtime: 10.253974914550781 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "deep_conv_rf_two_layer_acc_vs_n, deep_conv_rf_two_layer_acc_vs_n_times = list(zip(*run_experiment(run_two_layer_deep_conv_rf, \"deep_conv_rf_two_layer_acc_vs_n\", \"DeepConvRF (2-layer, shared)\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
